---
description: Core principles for writing effective prompts and instructions
globs:
  - "cofounder/tools/**"
  - "memory/my tools/**"
  - ".cursor/rules/*.mdc"
  - "**/AGENTS.md"
---

# Prompt Standards

Core principles for writing prompts, AGENTS.md files, and instruction documents.

**For full methodology:** See `/cofounder/tools/Prompt Author/AGENTS.md`

## The Elegance Principle

Maximum effect with minimum instruction. Most prompts fail by being too much, not too little.

**Threshold test:** Can you remove this instruction without degrading output quality? If yes, remove it.

**Structural clarity:** If your prompt repeats an instruction, the structure is wrong. Each instruction appears once, in the right place. If you find yourself restating, the structure is wrong.

**Communication insight:** Most prompt failures are communication failures, not LLM failures. A prompt that asks for clarification outperforms one that guesses wrong.

**Durability:** Prompts should leverage model intelligence, not compensate for model weakness.

## The Position Principle

Models attend most to beginning and end; middle receives less focus.

- **Opening:** Identity, objective, critical constraints
- **Middle:** Reference material, examples, domain knowledge
- **Closing:** Output format, success criteria, final reminders

Short prompts can ignore position; long prompts cannot.

## XML Boundaries

Separate instructions from user content. Prevents confusion between what to DO and what to process.

| Tag | Use For |
|-----|---------|
| `<user_request>` | What user asked for |
| `<source_material>` | Documents, transcripts, references |
| `<context>` | Background, constraints |

**Convention:** Descriptive, lowercase, underscores. Customize for your domain.

## Quality Checks

Before delivering any prompt or instruction document:

- [ ] **Evaluable:** Can you determine if output succeeded?
- [ ] **XML wrapped:** All user content in appropriate tags?
- [ ] **No failure modes:** See below
- [ ] **Threshold passed:** Nothing left to cut without degrading quality?
- [ ] **Position applied:** Critical at start, format at end?
- [ ] **Tested:** Run with real input to verify it works?

## Failure Modes

| Mode | Symptom | Fix |
|------|---------|-----|
| Vague objective | Inconsistent outputs | Define observable success criteria |
| Missing XML boundaries | Data confused with instructions | Wrap user content |
| Over-engineering | Model ignores parts | Apply threshold test |
| Positive content examples | Robotic output | Show structure, not content examples |
| Conflicting instructions | Random behavior | State priority; fix structure |
| No clarification path | Wrong output on ambiguity | Add "ask if unclear" |
| Critical buried in middle | Key instructions missed | Apply position principle |

## Clarification Over Guessing

Prompts should ask for clarity, not guess.

When ambiguity exists:
- Ask a clarifying question
- Offer 2-3 options for user to choose
- Surface what's unclear before proceeding

Include in prompts: "If the request is ambiguous, ask for clarification before proceeding."

The insight: User interaction makes good prompts great. Don't anticipate everything; create a dialogue.
